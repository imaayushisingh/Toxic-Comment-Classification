Takes input of comment from user and gives the output. For ex - 

Enter a comment:  I will kill you for this!

Classification Results:
toxic: 0.9819
severe_toxic: 0.0574
obscene: 0.0485
threat: 0.9694
insult: 0.1072
identity_hate: 0.0280
